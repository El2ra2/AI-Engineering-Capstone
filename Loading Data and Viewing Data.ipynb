{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8abd2f3a-7930-44bc-9a5f-3646677309bd",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \">\n",
    "</a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b80864-134b-4e19-b978-042c3752181d",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/image/IDSN-logo.png\" width=\"200\" alt=\"cognitiveclass.ai logo\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5bdfa8-6014-495e-af4c-1905a13cf122",
   "metadata": {},
   "source": [
    "<h1><h1>Pre-trained-Models with PyTorch </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53741054-55b8-4d99-9976-6032dbb90087",
   "metadata": {},
   "source": [
    "In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions: \n",
    "<ul>\n",
    "<li>change the output layer</li>\n",
    "<li> train the model</li> \n",
    "<li>  identify  several  misclassified samples</li> \n",
    " </ul>\n",
    "You will take several screenshots of your work and share your notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c08cf-34b0-406d-8125-0593277f34bc",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f07a2-6a2d-4608-84f2-0cc62bf2501b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#download_data\"> Download Data</a></li>\n",
    "    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n",
    "    <li><a href=\"#data_class\"> Dataset Class</a></li>\n",
    "    <li><a href=\"#Question_1\">Question 1</a></li>\n",
    "    <li><a href=\"#Question_2\">Question 2</a></li>\n",
    "    <li><a href=\"#Question_3\">Question 3</a></li>\n",
    "</ul>\n",
    "<p>Estimated Time Needed: <strong>120 min</strong></p>\n",
    " </div>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb7083-02ed-4c9c-b5b4-7b0418388a2a",
   "metadata": {},
   "source": [
    "<h2 id=\"download_data\">Download Data</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efedf9be-c643-4d62-8158-0918061c6b8b",
   "metadata": {},
   "source": [
    "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f119a703-4c0b-40c8-9ca9-152a26a98210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-11 15:47:36--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\n",
      "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
      "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2598656062 (2.4G) [application/zip]\n",
      "Saving to: ‘Positive_tensors.zip’\n",
      "\n",
      "Positive_tensors.zi 100%[===================>]   2.42G  32.6MB/s    in 77s     \n",
      "\n",
      "2024-05-11 15:48:53 (32.2 MB/s) - ‘Positive_tensors.zip’ saved [2598656062/2598656062]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f2804b-7bc0-4a34-a8bd-0756372003da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q Positive_tensors.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5119dc8-afc5-460d-879a-8b774f567bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-11 15:50:28--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
      "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
      "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2111408108 (2.0G) [application/zip]\n",
      "Saving to: ‘Negative_tensors.zip’\n",
      "\n",
      "Negative_tensors.zi 100%[===================>]   1.97G  35.4MB/s    in 60s     \n",
      "\n",
      "2024-05-11 15:51:28 (33.7 MB/s) - ‘Negative_tensors.zip’ saved [2111408108/2111408108]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
    "!unzip -q Negative_tensors.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad15709-e387-40fd-ab2f-8fde44dea3e1",
   "metadata": {},
   "source": [
    "We will install torchvision:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a4397a6-b3f6-4b0e-b9f9-c0e294eede06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from requests->torchvision) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from requests->torchvision) (2024.2.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from torch->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from torch->torchvision) (4.4.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from torch->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from torch->torchvision) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from torch->torchvision) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from jinja2->torch->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from sympy->torch->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720b2e1a-fa06-4daf-a922-4a70777f6709",
   "metadata": {},
   "source": [
    "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadbf87-12b4-4cf5-973b-d074375b21f7",
   "metadata": {},
   "source": [
    "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100c4913-0f97-425c-bf42-eba819ed5f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe861727750>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the libraries will be used for this lab.\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import pandas\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import torch \n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import os\n",
    "import glob\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62927ada-7de8-485c-a08e-cb2b038b25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed9c29-48b2-4bbf-9ba9-7f6fc1c088a2",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b81ceb-2ff9-4e71-b0ad-bcd507f91029",
   "metadata": {},
   "source": [
    "<h2 id=\"data_class\">Dataset Class</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8630dc80-3ee1-40a4-84d7-0427cd7101c7",
   "metadata": {},
   "source": [
    " This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c2612bc-5ed4-4f7d-bc9d-71c6a69ce2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create your own dataset object\n",
    "\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self,transform=None,train=True):\n",
    "        directory=\"/home/wsuser/work\"\n",
    "        positive=\"Positive_tensors\"\n",
    "        negative='Negative_tensors'\n",
    "\n",
    "        positive_file_path=os.path.join(directory,positive)\n",
    "        negative_file_path=os.path.join(directory,negative)\n",
    "        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n",
    "        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n",
    "        number_of_samples=len(positive_files)+len(negative_files)\n",
    "        self.all_files=[None]*number_of_samples\n",
    "        self.all_files[::2]=positive_files\n",
    "        self.all_files[1::2]=negative_files \n",
    "        # The transform is goint to be used on image\n",
    "        self.transform = transform\n",
    "        #torch.LongTensor\n",
    "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
    "        self.Y[::2]=1\n",
    "        self.Y[1::2]=0\n",
    "        \n",
    "        if train:\n",
    "            self.all_files=self.all_files[0:30000]\n",
    "            self.Y=self.Y[0:30000]\n",
    "            self.len=len(self.all_files)\n",
    "        else:\n",
    "            self.all_files=self.all_files[30000:]\n",
    "            self.Y=self.Y[30000:]\n",
    "            self.len=len(self.all_files)     \n",
    "       \n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "               \n",
    "        image=torch.load(self.all_files[idx])\n",
    "        y=self.Y[idx]\n",
    "                  \n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y, idx\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747173bb-89d3-45e8-b058-ab209f14610c",
   "metadata": {},
   "source": [
    "We create two dataset objects, one for the training data and one for the validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0618234d-d2a4-459a-aed0-20e3803a4661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train=True)\n",
    "validation_dataset = Dataset(train=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d6186-c5e3-4594-b469-fc776d407fe5",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_1\">Question 1</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c3bc6f-c9ce-4bc6-98e2-160b4c2c6be3",
   "metadata": {},
   "source": [
    "<b>Prepare a pre-trained resnet18 model :</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd3ebc-0de2-4418-9316-a20a12ec7034",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "293cde0f-d36f-4584-a1ff-d4fe736b9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the pre-trained model resnet18\n",
    "\n",
    "# Type your code here\n",
    "model= models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b310a4-2eb5-4627-ae5e-d0783ba838ad",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22ed14f3-ded5-47a6-b667-34e9d5bc0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set the parameter cannot be trained for the pre-trained model\n",
    "\n",
    "\n",
    "# Type your code here\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f23176-eca4-4e8f-9ec2-a164a5a7ef65",
   "metadata": {},
   "source": [
    "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410287ff-6594-4af8-8acc-495106d31545",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f79a8c7-4e3c-48b2-8d5c-75ec66fc7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc=nn.Linear(512,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048fe114-92ee-4c41-aede-1e016711ffcd",
   "metadata": {},
   "source": [
    "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1462f12b-da03-4175-ad74-043e46166410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb183bcf-8cfa-4e48-93e8-af78f42e57b0",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_2\">Question 2: Train the Model</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91768582-592a-4360-b47c-1c7db7008ff8",
   "metadata": {},
   "source": [
    "In this question you will train your, model:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455f1a9-a0af-4502-9179-0a4693cf06d8",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Create a cross entropy criterion function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5263c76f-483d-42bf-9716-c526278d3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the loss function\n",
    "\n",
    "# Type your code here\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f9645-a2ff-4900-91e7-4acf3eec2427",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f006c789-b1d6-4eb9-bdc4-613265ac440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=100)\n",
    "validation_loader=torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a965344-294c-4f35-881b-6f3b7e938149",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Use the following optimizer to minimize the loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ffbf141-4354-429f-ba64-cf0fecf4d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278f8e4c-8cc9-477a-b291-3aedf0d0852e",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f9e3b-f4a4-430d-92e4-2b204f4f9162",
   "metadata": {},
   "source": [
    "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e10db4f0-56f4-4c94-940f-133f5764ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=1\n",
    "loss_list=[]\n",
    "accuracy_list=[]\n",
    "correct=0\n",
    "N_test=len(validation_dataset)\n",
    "N_train=len(train_dataset)\n",
    "start_time = time.time()\n",
    "#n_epochs\n",
    "\n",
    "Loss=0\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    loss_sublist = []\n",
    "    for x, y, idx in train_loader:\n",
    "\n",
    "        #model.train() \n",
    "        #clear gradient \n",
    "        #optimizer.zero_grad()\n",
    "        #make a prediction \n",
    "        #z=model(x)\n",
    "        # calculate loss \n",
    "        #loss=criterion(z,y)\n",
    "        # calculate gradients of parameters \n",
    "        #loss.backward()\n",
    "        # update parameters \n",
    "        \n",
    "        #loss_list.append(loss.data)\n",
    "        \n",
    "        \n",
    "        model.train() \n",
    "        #clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        #make a prediction \n",
    "        z=model(x)\n",
    "        # calculate loss \n",
    "        loss=criterion(z,y)\n",
    "        loss_sublist.append(loss.data.item())\n",
    "        # calculate gradients of parameters \n",
    "        loss.backward()\n",
    "        # update parameters \n",
    "        optimizer.step()\n",
    "        loss_list.append(np.mean(loss_sublist))\n",
    "        \n",
    "    correct=0\n",
    "    for x_test, y_test, idx in validation_loader:\n",
    "        # set model to eval \n",
    "        model.eval()\n",
    "        #make a prediction \n",
    "        z=model(x_test)\n",
    "        #find max \n",
    "        yhat=torch.max(z.data,1)\n",
    "       \n",
    "        #Calculate misclassified  samples in mini-batch \n",
    "        #hint +=(yhat==y_test).sum().item()\n",
    "        if (yhat==y_test):\n",
    "            correct+=(yhat==y_test).sum().item()\n",
    "        #correct =correct + ((yhat==y_test).astype(int)).sum(1).item()\n",
    "        \n",
    "   \n",
    "    accuracy=correct/N_test\n",
    "    accuracy_list.append(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f3003-c65d-40bc-96ad-5c9c48c99f3b",
   "metadata": {},
   "source": [
    "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f321eee5-544b-4659-839f-0e6ea591d09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c7ae1d7-abbd-4e21-b0f2-9e45b967a1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1f6bc-f2ba-4b06-9109-7778966e1379",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a78f947-6f88-4871-8005-d5732cd8e2d9",
   "metadata": {},
   "source": [
    "<b>Identify the first four misclassified samples using the validation data:</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d0864db-4423-447e-b379-407e707efb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 87 yhat: tensor([1]) y:tensor([0])\n",
      "sample 463 yhat: tensor([1]) y:tensor([0])\n",
      "sample 685 yhat: tensor([1]) y:tensor([0])\n",
      "sample 1030 yhat: tensor([0]) y:tensor([1])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=1)\n",
    "\n",
    "# Plot the misclassified samples\n",
    "count = 0\n",
    "for (x_test, y_test, idx) in validation_loader:\n",
    "    z = model(x_test.reshape(-1,3,224,224))\n",
    "    _,yhat = torch.max(z.data, 1)\n",
    "    if yhat != y_test:\n",
    "        print(\"sample {} yhat: {} y:{}\".format(tf.reshape(idx, []), yhat, y_test))\n",
    "        count += 1\n",
    "    if count >= 4:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715b8fe6-26bd-4bb9-b8da-1ca492528ee6",
   "metadata": {},
   "source": [
    "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html?utm_source=Exinfluencer&utm_content=000026UJ&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01&utm_medium=Exinfluencer&utm_term=10006555\"> CLICK HERE </a> Click here to see how to share your notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f20a3f-7d1b-4aea-9e74-e373ec30e1bb",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb64cce-3fe5-489d-bced-79c3e7a447cf",
   "metadata": {},
   "source": [
    "\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2020-09-21  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
    "\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a379170-e56f-40f9-9f8f-e3227416419a",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\">MIT License</a>.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
